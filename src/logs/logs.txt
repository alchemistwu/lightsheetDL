0: train_loss=0.41082377547628424, val_loss=0.3099275248555037, train_acc=0.9194384813308716, val_acc=0.9299837350845337
1: train_loss=0.24591416806987162, val_loss=0.2162386994713392, train_acc=0.949691653251648, val_acc=0.9473062753677368
2: train_loss=0.1876129868947101, val_loss=0.2626181764002794, train_acc=0.9561282396316528, val_acc=0.9130982756614685
3: train_loss=0.15800572555051762, val_loss=0.153003119600889, train_acc=0.9574406147003174, val_acc=0.9571644067764282
4: train_loss=0.14343125237986135, val_loss=0.1735800540026946, train_acc=0.9596128463745117, val_acc=0.9410578012466431
5: train_loss=0.13352998642678438, val_loss=0.16322291117065993, train_acc=0.960177481174469, val_acc=0.9499025344848633
6: train_loss=0.134979334159083, val_loss=0.14922545597148248, train_acc=0.9608421921730042, val_acc=0.9542356133460999
7: train_loss=0.1337732659655819, val_loss=0.1525618905822436, train_acc=0.9608442783355713, val_acc=0.9544399976730347
8: train_loss=0.12507916272978148, val_loss=0.12413463211403443, train_acc=0.9626064896583557, val_acc=0.9606350660324097
9: train_loss=0.12145538653215665, val_loss=0.2858668220921969, train_acc=0.9625974893569946, val_acc=0.9134398102760315
10: train_loss=0.11924757181784888, val_loss=0.13771835356377637, train_acc=0.9631441831588745, val_acc=0.9527981877326965
11: train_loss=0.11787208223515108, val_loss=0.12290406131591552, train_acc=0.9637736082077026, val_acc=0.9582556486129761
12: train_loss=0.11744702065043618, val_loss=0.14172437844368127, train_acc=0.9638742804527283, val_acc=0.9558247327804565
13: train_loss=0.11920785300589105, val_loss=0.12975037002410644, train_acc=0.963771402835846, val_acc=0.958882749080658
14: train_loss=0.11598373128528772, val_loss=0.12506128527606145, train_acc=0.9640172719955444, val_acc=0.9592874050140381
15: train_loss=0.11809452159709953, val_loss=0.1369311680109837, train_acc=0.9644588232040405, val_acc=0.9548375010490417
16: train_loss=0.1140990558455595, val_loss=0.11790109409067111, train_acc=0.9644260406494141, val_acc=0.9592770338058472
17: train_loss=0.12371310262221777, val_loss=0.1292735517789156, train_acc=0.9633997082710266, val_acc=0.9587505459785461
18: train_loss=0.11464873744387113, val_loss=0.12159834422457677, train_acc=0.9646816253662109, val_acc=0.9612942337989807
19: train_loss=0.11938869321111882, val_loss=0.13617123159556052, train_acc=0.9640287756919861, val_acc=0.9574359655380249
20: train_loss=0.11450701470024896, val_loss=0.13021389636187217, train_acc=0.9654619693756104, val_acc=0.9601616859436035
21: train_loss=0.10858551997625618, val_loss=0.12406517047052965, train_acc=0.9654823541641235, val_acc=0.956784725189209
22: train_loss=0.1149142851505913, val_loss=0.12227915088908795, train_acc=0.964965283870697, val_acc=0.9614200592041016
23: train_loss=0.11166757547310038, val_loss=0.11483177595222607, train_acc=0.9654480218887329, val_acc=0.962136447429657
24: train_loss=0.11118385818208393, val_loss=0.11572821089663567, train_acc=0.9657449126243591, val_acc=0.9629719853401184
25: train_loss=0.10726472855594912, val_loss=0.12901958355154747, train_acc=0.9661697745323181, val_acc=0.9582136273384094
26: train_loss=0.10994149843473017, val_loss=0.13993333740971792, train_acc=0.9657270312309265, val_acc=0.9577447772026062
27: train_loss=0.10847030255650536, val_loss=0.12817347806711227, train_acc=0.9661626815795898, val_acc=0.9555182456970215
28: train_loss=0.10993927853543724, val_loss=0.12498706323691668, train_acc=0.9659079909324646, val_acc=0.9606485366821289
29: train_loss=0.10757597461701587, val_loss=0.10920326027255027, train_acc=0.9659762978553772, val_acc=0.9624696969985962
30: train_loss=0.11067071748392157, val_loss=0.12721196125046566, train_acc=0.9661576151847839, val_acc=0.9593686461448669
31: train_loss=0.10602959171296314, val_loss=0.11768881231546402, train_acc=0.9667571187019348, val_acc=0.9620800614356995
32: train_loss=0.10492278332934142, val_loss=0.15136797831226617, train_acc=0.9668955206871033, val_acc=0.9506368041038513
33: train_loss=0.1052154234728595, val_loss=0.11487125696089023, train_acc=0.96650630235672, val_acc=0.9636593461036682
34: train_loss=0.1037026115216279, val_loss=0.13581373929404295, train_acc=0.9669602513313293, val_acc=0.9576395153999329
35: train_loss=0.11822965400918338, val_loss=0.1189864836872006, train_acc=0.9642944931983948, val_acc=0.9615991711616516
36: train_loss=0.10497396984653336, val_loss=0.11465362920306432, train_acc=0.9668444991111755, val_acc=0.9622310400009155
37: train_loss=0.10390563683814547, val_loss=0.15717509384147632, train_acc=0.9664687514305115, val_acc=0.9500410556793213
38: train_loss=0.10242751011113677, val_loss=0.1154778016707263, train_acc=0.9672627449035645, val_acc=0.9630258679389954
39: train_loss=0.10596020567570223, val_loss=0.11262422874092291, train_acc=0.9671519994735718, val_acc=0.9625120759010315
40: train_loss=0.10417804008358746, val_loss=0.1361440465045281, train_acc=0.967114269733429, val_acc=0.9580396413803101
41: train_loss=0.10750343049629733, val_loss=0.11916406189975066, train_acc=0.9671643376350403, val_acc=0.9599742293357849
42: train_loss=0.1060626335071331, val_loss=0.11758588295047864, train_acc=0.9671893119812012, val_acc=0.9601906538009644
43: train_loss=0.10141613682430016, val_loss=0.11791178116049522, train_acc=0.9678357243537903, val_acc=0.9609226584434509
44: train_loss=0.10226314488266196, val_loss=0.12574270990892097, train_acc=0.968066394329071, val_acc=0.9601511359214783
45: train_loss=0.1026358392304871, val_loss=0.13441353448881552, train_acc=0.9678270816802979, val_acc=0.9521942138671875
46: train_loss=0.10199448690535934, val_loss=0.11873053319943257, train_acc=0.9678022861480713, val_acc=0.9593942761421204
47: train_loss=0.10367021585005914, val_loss=0.10558590355018775, train_acc=0.9682700634002686, val_acc=0.9637638926506042
48: train_loss=0.10393028808862306, val_loss=0.09955208607686636, train_acc=0.9670386910438538, val_acc=0.96785968542099
49: train_loss=0.10317205048104924, val_loss=0.17805701061987725, train_acc=0.9681356549263, val_acc=0.9407098293304443
50: train_loss=0.10242900346221931, val_loss=0.10946746352009284, train_acc=0.967917263507843, val_acc=0.9629408717155457
51: train_loss=0.09894157468040816, val_loss=0.1195634732213922, train_acc=0.9685946702957153, val_acc=0.9581222534179688
52: train_loss=0.10309349869887673, val_loss=0.11361205549194263, train_acc=0.968172550201416, val_acc=0.9606833457946777
53: train_loss=0.09994570334497271, val_loss=0.13639096801097578, train_acc=0.9675089120864868, val_acc=0.9509968161582947
54: train_loss=0.10178819041621437, val_loss=0.13038187965941736, train_acc=0.9684931039810181, val_acc=0.9581736922264099
55: train_loss=0.10285955703074343, val_loss=0.11380488099530339, train_acc=0.9682530760765076, val_acc=0.9619090557098389
56: train_loss=0.09835654686101941, val_loss=0.11702904728456186, train_acc=0.9684668779373169, val_acc=0.9637641906738281
57: train_loss=0.10087385733595437, val_loss=0.11251250738039231, train_acc=0.9683412909507751, val_acc=0.962749183177948
58: train_loss=0.10233602096680941, val_loss=0.11229211003638995, train_acc=0.9683341383934021, val_acc=0.9622993469238281
59: train_loss=0.09995686534917757, val_loss=0.13743321779064643, train_acc=0.9684943556785583, val_acc=0.9570058584213257
60: train_loss=0.09956209029685437, val_loss=0.15394802463169283, train_acc=0.9685930013656616, val_acc=0.9514559507369995
61: train_loss=0.09944214247298662, val_loss=0.11495835513163072, train_acc=0.9690023064613342, val_acc=0.9627024531364441
62: train_loss=0.09752007832759647, val_loss=0.10907785668491553, train_acc=0.9690700769424438, val_acc=0.9634566307067871
63: train_loss=0.11340068412547032, val_loss=0.11048735328352986, train_acc=0.9671792387962341, val_acc=0.9628455638885498
64: train_loss=0.09768535832711533, val_loss=0.3288458754810003, train_acc=0.9693740606307983, val_acc=0.9145109057426453
65: train_loss=0.09850765319233147, val_loss=0.11643249997630334, train_acc=0.9693001508712769, val_acc=0.9607940912246704
66: train_loss=0.10268100815112097, val_loss=0.1415615951976715, train_acc=0.9693689942359924, val_acc=0.9578943252563477
67: train_loss=0.09515980949825689, val_loss=0.13975303892332774, train_acc=0.9696511030197144, val_acc=0.9541212916374207
68: train_loss=0.09741586992400511, val_loss=0.12521701098348087, train_acc=0.9687498211860657, val_acc=0.9602794051170349
69: train_loss=0.0995957176014183, val_loss=0.11943777134785286, train_acc=0.9692212343215942, val_acc=0.9593887329101562
70: train_loss=0.09660118022398428, val_loss=0.16169870496751407, train_acc=0.9690282344818115, val_acc=0.9549251198768616
71: train_loss=0.09559136618939296, val_loss=0.13825277659373406, train_acc=0.9694539308547974, val_acc=0.9548046588897705
72: train_loss=0.0957960102402188, val_loss=0.16571861150889441, train_acc=0.9683842062950134, val_acc=0.9552271962165833
73: train_loss=0.09401222769571632, val_loss=0.11055369727695599, train_acc=0.9700597524642944, val_acc=0.9639855623245239
74: train_loss=0.0921020365767121, val_loss=0.13018339392370903, train_acc=0.9693078994750977, val_acc=0.9614149928092957
75: train_loss=0.09296977087365012, val_loss=0.15478345121328646, train_acc=0.9697237610816956, val_acc=0.9546530246734619
76: train_loss=0.09996111393513017, val_loss=0.13187294295774057, train_acc=0.9673006534576416, val_acc=0.9595832228660583
77: train_loss=0.0945085979980173, val_loss=0.18140322762804154, train_acc=0.9701949954032898, val_acc=0.950061023235321
78: train_loss=0.09167206290373833, val_loss=0.13947695116393077, train_acc=0.9703425168991089, val_acc=0.9569265246391296
79: train_loss=0.09299218916539014, val_loss=0.13512195035433158, train_acc=0.9705599546432495, val_acc=0.9619582891464233
80: train_loss=0.0907379404116978, val_loss=0.11449771271779752, train_acc=0.9702688455581665, val_acc=0.9631649255752563
81: train_loss=0.09232631085042874, val_loss=0.18531872754773268, train_acc=0.9708989858627319, val_acc=0.9536147117614746
82: train_loss=0.09321949076666877, val_loss=0.12348538618057202, train_acc=0.970382809638977, val_acc=0.9595137238502502
83: train_loss=0.0920041517906166, val_loss=0.1272589853988626, train_acc=0.9701065421104431, val_acc=0.9605922102928162
84: train_loss=0.0998746512388963, val_loss=0.13601863317382643, train_acc=0.9705572128295898, val_acc=0.9575980305671692
85: train_loss=0.08782887117964115, val_loss=0.12124250342066471, train_acc=0.9711951017379761, val_acc=0.9622836112976074
86: train_loss=0.0903003297112344, val_loss=0.12117920526995873, train_acc=0.9710928201675415, val_acc=0.9603816270828247
87: train_loss=0.08944016770290789, val_loss=0.10846857855526301, train_acc=0.9704601168632507, val_acc=0.9647809267044067
88: train_loss=0.08456765708138338, val_loss=0.16283939941189227, train_acc=0.9710520505905151, val_acc=0.9605408310890198
89: train_loss=0.09199806826299783, val_loss=0.16829562244506982, train_acc=0.9710991382598877, val_acc=0.9474627375602722
90: train_loss=0.0850918624239165, val_loss=0.1425343135562845, train_acc=0.9714272022247314, val_acc=0.9597824215888977
91: train_loss=0.0871644134948667, val_loss=0.13863573029923898, train_acc=0.970895528793335, val_acc=0.9605148434638977
92: train_loss=0.08519206378447493, val_loss=0.13254505137984568, train_acc=0.97183758020401, val_acc=0.9620498418807983
93: train_loss=0.08570384721228341, val_loss=0.15506068816504034, train_acc=0.9711072444915771, val_acc=0.9584888815879822
94: train_loss=0.09524555545880266, val_loss=0.12242520278176436, train_acc=0.9705737233161926, val_acc=0.9647183418273926
95: train_loss=0.08672104188111009, val_loss=0.17218523147778633, train_acc=0.9715927243232727, val_acc=0.9541796445846558
96: train_loss=0.0943839115301449, val_loss=0.14243243364856029, train_acc=0.9709193110466003, val_acc=0.960618793964386
97: train_loss=0.08340578082273228, val_loss=0.12640110749560288, train_acc=0.9720188975334167, val_acc=0.9630779027938843
98: train_loss=0.08600426471700973, val_loss=0.147553669121594, train_acc=0.9705449938774109, val_acc=0.9561523795127869
99: train_loss=0.09069787533609959, val_loss=0.14511544297998533, train_acc=0.9716904163360596, val_acc=0.9616146087646484
